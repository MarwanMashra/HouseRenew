{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a1bc5f",
   "metadata": {},
   "source": [
    "GROUP NAME  \n",
    "\n",
    "HI!CKATHON 2023\n",
    "\n",
    "Date  \n",
    "\n",
    "# I.\tOVERVIEW\n",
    "## 1.\tProject Background and Description\n",
    " \tDescribe how this project came about, and the purpose.\n",
    "Nowadays geopolitical reasons make us look back to the concern of energy saving, governements have applied measures in different sectors to obtain actual reductions however, building energy represents around 45% of total energy consumption, consequentely major efforts should be focused on this sector. Current approaches to help particular householders are still few and improvable, specially for householders living on outside areas. A data set continaing 71 explicative variables was given to us to find the answer of what actions and features contribuite to energy sobriety in buildings, but above all to find a simple way to decrease the excess of energy.\n",
    "## 2.\tProject Scope\n",
    " \t Scope answers questions including what will be done, what won’t be done, and what the result will look like.\n",
    "\n",
    "With House Renew, we position ourselves as a proximity facilitator to support the energy transition process for individual homes. Mirroring the action of public authorities, we base ourselves on an estimate of the future consumption of a building (85% accuracy score reached thanks to AI), we help the individual and the co-ownership to evaluate the impact of an energy renovation. Through a website and with regard to the announced budget, we aim to complete the estimate made online by prioritizing the most effective renovations to reduce the consumption of the building. In the medium term, we aim to expand geographically to an European level as well as to canvass public actors already committed to supporting the energy transition.\n",
    "\n",
    "\n",
    "## 3.\tPresentation of the group\n",
    " \tInclude your specialization at school, etc.\n",
    "\n",
    "| First name | Last name | Year of studies & Profile | School | Skills | Roles/Tasks | Observations |\n",
    "| ---------- | --------- | ------------------------- | ------ | ------ | ----------- | ------------ |\n",
    "| Luc    | Gensbittel  |M2 Data sciences  | IP Paris | Management, data sciences | idem     | Do always as to be proud of what you do |\n",
    "| Marisol    | Jiménez  |M2 MSID  | UPPA | Data extraction, statistiques | Data scientist, integration of tasks    |\n",
    "| Marwan  | Mashra  |M2 AI  | Université Paris-Saclay | ML, problem solving  | idem     | AI should have an impact |   |\n",
    "\n",
    "\n",
    "\n",
    "## 4.\tTask Management\n",
    " \tDescribe how you interacted and collaborated as a team, and the effect of every member’s unique background on the project.\n",
    "We are \"House Renew 17\", a group of 5 students with complementary skillsets. We divided the group into 2 teams, a technical team and a business team. With 3 data scientist, our Technical Team was in charge of developing the AI engine of the project. It relies on Marwan Mashra, M2-student at Paris-Saclay university, Marisol Jimenez our Mexican M2 data science student from the Pau university, and Luc Gensbittel, our team dean that is resuming his studies from the military world at IP Paris. They used different approaches to enhance the global performance, especially by cleaning and preprocessing data while bench-marking all the AI state-of-the-art methods. Robustness and frugality were their moto. On the Business team there were two true business leaders, starting with Alexis…. And Lorentz …\n",
    "\n",
    "\n",
    "Alexis focused on building a website, shooting and editing video, Lorentz developed a strong business plan, while chiseling our video’s script.  \n",
    "\n",
    "\n",
    "# II.\tPROJECT MANAGEMENT\n",
    "## 1.\tData Understanding\n",
    " \tProvided the initial collection of data has already occurred, \n",
    "    this step includes identifying and defining the relevant data, exploring the range, scale, formats, contents, and biases of the data, and evaluating the quality and validity of the resulting data.\n",
    "We started by exploring the correlation matrix between target and the features to find the most relevant ones to the model. Then, we detected the number of NAS per feature to decide how to handle those values, taking on acount the contribution of each feature to the model, for example, the feature building_year had almost 7% of missing values while it contributed largely to the model, however the variable building_period had a 0% of missing values, given the fact that they were mostly correlated we wondered if we could complete one with the help of the other. We also identified mainly two types of data: numeric and categorical data and proceeded with a separate treatment for each of them. Regarding the biases, we plotted the target values and found relatevily few outliers meaning we could get rid of them without a great loss of information.\n",
    "\n",
    "## 2.\tData Pre-processing\n",
    " \tExplain how the selection of data was manipulated and modified to remove redundant features and improve the quality of the data. Describe the preprocessing techniques used, such as data augmentation.\n",
    "The first thing to clean our data set was treatement of missing values, instead of just deleting those rows we aimed to complete the missing values with the help of similar variables. Retaking the case of NAs in the feature building_year, we filled them with the corresponding mean of each building_period, however we found that for the categories 2000-2005 and 2006-2012 the mean was under 2000 which made no sense, in those two categories we took instead the mode. To remove redundant and irrelevant features we relied on the percentage of NAs, for example the feature gas_meters_total had almost 99% of NAs which meant it was not adding any information at all! We deleted the features on a similar situation. \n",
    "\n",
    "Secondly, we focused on understanding the meaning of NAs in the feature, was it a missing value? or a category that did not belong to any of the others. In heating_device feature we discovered that a missing value could mean there was no heating device which was different to say we did not have the information, in this case we attributed them a new category. Another case was the nan values on the feature balcony depth which meant there was no balcony at all, so it measure was actually zero. For some features, there was already a category for other, so we assigned this category to the missing values. We applied hot encoding for categorical features and for numerical ones we assigned them its mean, finally we deleted the remaining rows containing nan values as they represented a considerable low percentage. We ended up with approximately 600,000 rows. \n",
    "\n",
    "Regarding the outliers we placed max and min limits based on the plot of our target value.\n",
    "\n",
    "\n",
    "## 3.\tModeling Development\n",
    " \tDescribe how you selected algorithms, how you calibrated them according to the data and how - in fine - you selected the best AI model using a well-defined set of metrics.\n",
    "\n",
    "We focused on a quick adjustment of the model to see a general behavior of our data training, get a variance to improve and above of all identify globally the important feautres of wich the business team could start to develop our During our first trial implemented the model of XGBoosting because it is the most used for data with random forests and parametres par default, we got a explained variance of 81%, after changin the parametres and seeing no big changes on hte predictions we returned to the cleaning of the data to improve the model.\n",
    "\n",
    "## 4.\t Deployment Strategy\n",
    " \tWhat best practices/norms did you follow? How do you plan on deploying your IA solution?\n",
    "Enter your answer here.\n",
    "\n",
    "\n",
    "# III.\tCARBON FOOTPRINT LIMITATION\n",
    " \tDescribe the taken measures/actions during the development of your solution in view of limiting the carbon footprint.\n",
    "By keeeping only relevant columns we do not only assure a more accurate reponse but also levering\n",
    "\n",
    "\n",
    "# IV.\tCONCLUSION\n",
    " \tTell us about the actual results, their limitations as well as future perspectives and improvements.\n",
    "Enter your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05f0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nbconvert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
